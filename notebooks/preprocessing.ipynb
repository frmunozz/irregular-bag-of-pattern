{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(str(os.getcwd()), '..', 'data')\n",
    "df = pd.read_csv(os.path.join(data_path, \"training_set.csv.zip\"))\n",
    "df_meta = pd.read_csv(os.path.join(data_path, \"training_set_metadata.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>decl</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>mwebv</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615</td>\n",
       "      <td>349.046051</td>\n",
       "      <td>-61.943836</td>\n",
       "      <td>320.796530</td>\n",
       "      <td>-51.753706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713</td>\n",
       "      <td>53.085938</td>\n",
       "      <td>-27.784405</td>\n",
       "      <td>223.525509</td>\n",
       "      <td>-54.460748</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8181</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>45.4063</td>\n",
       "      <td>0.007</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>33.574219</td>\n",
       "      <td>-6.579593</td>\n",
       "      <td>170.455585</td>\n",
       "      <td>-61.548219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>40.2561</td>\n",
       "      <td>0.021</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745</td>\n",
       "      <td>0.189873</td>\n",
       "      <td>-45.586655</td>\n",
       "      <td>328.254458</td>\n",
       "      <td>-68.969298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>40.7951</td>\n",
       "      <td>0.007</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124</td>\n",
       "      <td>352.711273</td>\n",
       "      <td>-63.823658</td>\n",
       "      <td>316.922299</td>\n",
       "      <td>-51.059403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>40.4166</td>\n",
       "      <td>0.024</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id          ra       decl       gal_l      gal_b  ddf  \\\n",
       "0        615  349.046051 -61.943836  320.796530 -51.753706    1   \n",
       "1        713   53.085938 -27.784405  223.525509 -54.460748    1   \n",
       "2        730   33.574219  -6.579593  170.455585 -61.548219    1   \n",
       "3        745    0.189873 -45.586655  328.254458 -68.969298    1   \n",
       "4       1124  352.711273 -63.823658  316.922299 -51.059403    1   \n",
       "\n",
       "   hostgal_specz  hostgal_photoz  hostgal_photoz_err  distmod  mwebv  target  \n",
       "0         0.0000          0.0000              0.0000      NaN  0.017      92  \n",
       "1         1.8181          1.6267              0.2552  45.4063  0.007      88  \n",
       "2         0.2320          0.2262              0.0157  40.2561  0.021      42  \n",
       "3         0.3037          0.2813              1.1523  40.7951  0.007      90  \n",
       "4         0.1934          0.2415              0.0176  40.4166  0.024      90  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of timeseries per class')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_count = defaultdict(int)\n",
    "for l in df_meta[\"target\"]:\n",
    "    class_count[l] += 1\n",
    "    \n",
    "labels_cc, values_cc = zip(*class_count.items())\n",
    "indexes = np.arange(len(labels_cc))\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "plt.bar(indexes, values_cc)\n",
    "plt.xticks(indexes, labels_cc)\n",
    "plt.xlabel(\"class\", fontsize=15)\n",
    "plt.ylabel(\"count\", fontsize=15)\n",
    "plt.title(\"Number of timeseries per class\", fontsize=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first reduction: number of classes\n",
    "\n",
    "as a first preprocessing step, we will discard every class with less than a fixed number of time series in order to make a more simplest dataset for testing reducing the number of classes with small amount of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surviving classes are: [15 16 42 62 65 90]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6390"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 400\n",
    "df_meta = df_meta.sort_values(by=[\"target\"])\n",
    "df_meta_filtered = df_meta[df_meta['target'].map(df_meta['target'].value_counts()) >= threshold]\n",
    "classes = np.unique(df_meta_filtered[\"target\"])\n",
    "print(\"surviving classes are:\", classes)\n",
    "df_meta_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we take time series fro the passband '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "passband_id = 3\n",
    "\n",
    "df = df[df[\"passband\"] == passband_id]\n",
    "df = df.sort_values(by=[\"object_id\", \"mjd\"])\n",
    "df_grouped = df.groupby(\"object_id\")\n",
    "fluxes = df_grouped[\"flux\"].apply(list)\n",
    "mjds = df_grouped[\"mjd\"].apply(list)\n",
    "labels = []\n",
    "dataset = []\n",
    "times = []\n",
    "for i in range(df_meta_filtered.shape[0]):\n",
    "    row = df_meta_filtered.iloc[i]\n",
    "    object_id = row.object_id\n",
    "    target = row.target\n",
    "    labels.append(target)\n",
    "    dataset.append(np.array(fluxes.loc[object_id]))\n",
    "    times.append(np.array(mjds.loc[object_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second reduction: train/test data size\n",
    "\n",
    "since at first we will use non-optimize solutions which will take lot of time to execute, we will start evaluating our experimentes on small sub-sets from the original dataset. From here, we will test three scenarios:\n",
    "\n",
    "1. constant train/test set ratio but increasing the number of timeseries\n",
    "2. constant test set size but increasing the size of train set\n",
    "3. constant train set size but increasing the size of the test set\n",
    "\n",
    "in particular here, for the 3rd scenario we will just have to fix the train set size and get a test size as big as posible, then on evaluation process we will take only sub-sets of this test set\n",
    "\n",
    "for the 2nd scenario, we will fix the test set size on 1/3 of the maximum train set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_dataset(dataset, times, labels, n1, n2):\n",
    "    # n: size of the small dataset\n",
    "    # c: use the 'c' classes most present in the original dataset\n",
    "    \n",
    "    data_time_tuple = [(t, y) for t, y in zip(times, dataset)]\n",
    "    \n",
    "    # first split, to get n1+n2 set size\n",
    "    if n1+n2 < len(labels) - np.unique(labels).size:\n",
    "    \n",
    "         _, data_time_tuple, _,  labels = train_test_split(data_time_tuple, labels,\n",
    "                                                    test_size=n1 + n2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=labels)\n",
    "        \n",
    "    # second split, to get train n1 and test n2\n",
    "    data_time_train, data_time_test, labels_train, labels_test = train_test_split(data_time_tuple,\n",
    "                                                                                 labels,\n",
    "                                                                                 test_size=n2,\n",
    "                                                                                 random_state=0,\n",
    "                                                                                 stratify=labels)\n",
    "    d_train = []\n",
    "    d_test = []\n",
    "    t_train = []\n",
    "    t_test = []\n",
    "    for i in range(n1):\n",
    "        t, d = data_time_train[i]\n",
    "        d_train.append(d)\n",
    "        t_train.append(t)\n",
    "        \n",
    "    for i in range(n2):\n",
    "        t, d = data_time_test[i]\n",
    "        d_test.append(d)\n",
    "        t_test.append(t)\n",
    "\n",
    "    \n",
    "    return d_train, t_train, labels_train, d_test, t_test, labels_test\n",
    "\n",
    "\n",
    "def gen_sub_sets(output_path, dataset, times, labels, n1_arr, n2_arr, c):\n",
    "    for n1, n2 in zip(n1_arr, n2_arr):\n",
    "        d_train, t_train, l_train, d_test, t_test, l_test = get_small_dataset(dataset, times, labels,\n",
    "                                                                             n1, n2)\n",
    "        skip = False\n",
    "        for type_i, data_i in zip([\"d\", \"t\", \"l\"],\n",
    "                                  [(d_train, d_test), (t_train, t_test), (l_train, l_test)]):\n",
    "            out_file_train = os.path.join(output_path, \"train_{}_n{}_c{}.npy\".format(type_i, n1, c))\n",
    "            out_file_test = os.path.join(output_path, \"test_{}_n{}_c{}.npy\".format(type_i, n2, c))\n",
    "            if not os.path.exists(out_file_train):\n",
    "                np.save(out_file_train, data_i[0])\n",
    "                np.save(out_file_test, data_i[1])\n",
    "            else:\n",
    "                skip = True\n",
    "                break\n",
    "        if not skip:\n",
    "            print(\":::GEN [train, test, classes] = [%d, %d, %d] set on dir %s\" % (n1, n2, c, output_path))\n",
    "        else:\n",
    "            print(\":::SKIP [train, test, classes] = [%d, %d, %d]\" % (n1, n2, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::GEN [train, test, classes] = [100, 25, 6] set on dir D:\\tesis\\tesis\\notebooks\\..\\data\\plasticc_subsets\\scenario1_ratio_2-8\n",
      ":::GEN [train, test, classes] = [500, 125, 6] set on dir D:\\tesis\\tesis\\notebooks\\..\\data\\plasticc_subsets\\scenario1_ratio_2-8\n",
      ":::GEN [train, test, classes] = [1000, 250, 6] set on dir D:\\tesis\\tesis\\notebooks\\..\\data\\plasticc_subsets\\scenario1_ratio_2-8\n",
      ":::GEN [train, test, classes] = [2000, 500, 6] set on dir D:\\tesis\\tesis\\notebooks\\..\\data\\plasticc_subsets\\scenario1_ratio_2-8\n",
      ":::GEN [train, test, classes] = [4000, 1000, 6] set on dir D:\\tesis\\tesis\\notebooks\\..\\data\\plasticc_subsets\\scenario1_ratio_2-8\n",
      ":::GEN [train, test, classes] = [5000, 1250, 6] set on dir D:\\tesis\\tesis\\notebooks\\..\\data\\plasticc_subsets\\scenario1_ratio_2-8\n"
     ]
    }
   ],
   "source": [
    "# 1st scenario\n",
    "ratio = 2/8 # 20% test, 80% train\n",
    "n1_arr = np.array([100, 500, 1000, 2000, 4000, 5000], dtype=int)\n",
    "n2_arr = (n1_arr * ratio).astype(int)\n",
    "output_path1 = os.path.join(data_path, \"plasticc_subsets\", \"scenario1_ratio_2-8\")\n",
    "gen_sub_sets(output_path1, dataset, times, labels, n1_arr, n2_arr, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
