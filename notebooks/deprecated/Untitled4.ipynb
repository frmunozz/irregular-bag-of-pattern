{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_main_test_ucr_p1(train_file, test_file, wd_arr, wl_arr, out_q):\n",
    "    try:\n",
    "        print(\"start worker\")\n",
    "        wd_num = len(wd_arr)\n",
    "        wl_num = len(wl_arr)\n",
    "    \n",
    "        bopf = BagOfPatternFeature()\n",
    "        bopf.load_dataset(train_file, fmt=\"file\")\n",
    "        bopf.cumsum()\n",
    "    \n",
    "        bopf_t = BagOfPatternFeature()\n",
    "        bopf_t.load_dataset(test_file, fmt=\"file\")\n",
    "        bopf_t.cumsum()\n",
    "    \n",
    "        output_dict = defaultdict(list)\n",
    "    \n",
    "        for i in range(wd_num):\n",
    "            wd = wd_arr[i]\n",
    "            for j in range(wl_num):\n",
    "                wl = wl_arr[j]\n",
    "                bopf.bop(wd, wl, verbose=False)\n",
    "                bopf.adjust_label_set()\n",
    "                bopf.anova(verbose=False)\n",
    "                bopf.anova_sort()\n",
    "                bopf.sort_trim_arr(verbose=False)\n",
    "                bopf.crossVL(verbose=False)\n",
    "                output_dict[\"bop_features\"].append(bopf.crossL[:bopf.c*bopf.best_idx])\n",
    "                output_dict[\"bop_fea_num\"].append(bopf.best_idx)\n",
    "                output_dict[\"bop_cv_acc\"].append(bopf.best_score)\n",
    "                output_dict[\"bop_feature_index\"].append(bopf.sort_index[:bopf.best_idx])\n",
    "            \n",
    "                bopf.crossVL2()\n",
    "                output_dict[\"bop_features2\"].append(bopf.crossL2[:bopf.c*bopf.best2_idx])\n",
    "                output_dict[\"bop_fea_num2\"].append(bopf.best2_idx)\n",
    "                output_dict[\"bop_cv_acc2\"].append(bopf.best2_score)\n",
    "                output_dict[\"bop_feature_index2\"].append(bopf.sort_index[:bopf.best2_idx])\n",
    "            \n",
    "                output_dict[\"bop_wd\"].append(wd)\n",
    "                output_dict[\"bop_wl\"].append(wl)\n",
    "        \n",
    "        out_q.put((wl_arr[0], wl_arr[-1], output_dict))\n",
    "    except:\n",
    "        print(\"worker failed\")\n",
    "    finally:\n",
    "        print(\"done\")\n",
    "    \n",
    "    \n",
    "\n",
    "def main_test_ucr_p1_multiprocess(train_file, test_file, wd_arr, wl_arr):\n",
    "    m = mp.Manager()\n",
    "    result_queue = m.Queue()\n",
    "    \n",
    "    N = 1 + (len(wl_arr) // n_process)\n",
    "    \n",
    "    for k in range(n_process):\n",
    "        i = k*N\n",
    "        j = (k+1)*N\n",
    "        if j > len(wl_arr):\n",
    "            j = len(wl_arr)\n",
    "        wl_sub_arr = wl_arr[i:j]\n",
    "        jobs.append(mp.Process(target=worker_main_test_ucr_p1, \n",
    "                               args=(train_file, test_file, wd_arr, wl_sub_arr, result_queue)))\n",
    "        jobs[-1].start()\n",
    "    \n",
    "    return bopf, bopf_t, output_dict\n",
    "\n",
    "def worker_main_test_ucr_p2(i, j, index1, index2, output_dict, bopf, test_file, out_q):\n",
    "    \n",
    "    bopf_t = BagOfPatternFeature()\n",
    "    bopf_t.load_dataset(test_file, fmt=\"file\")\n",
    "    bopf_t.cumsum()\n",
    "    \n",
    "    best_centroid = -1\n",
    "    best_tf_idf = -1\n",
    "    rbest_centroid = -np.inf\n",
    "    rbest_tf_idf = -np.inf\n",
    "    for k in range(i, j):\n",
    "        s_index = index1[k]\n",
    "        wd = output_dict[\"bop_wd\"][s_index]\n",
    "        wl = output_dict[\"bop_wl\"][s_index]\n",
    "        bopf_t.bop(wd, wl, verbose=False)\n",
    "        test_bop_sort = sort_trim_arr(bopf_t.train_bop, output_dict[\"bop_feature_index\"][s_index], \n",
    "                                  bopf_t.m, output_dict[\"bop_fea_num\"][s_index])\n",
    "        predicted_label = classify(test_bop_sort, output_dict[\"bop_features\"][s_index], bopf.tlabel, \n",
    "                               bopf_t.m, bopf.c, output_dict[\"bop_fea_num\"][s_index])\n",
    "        real_label = np.array(bopf_t.labels)\n",
    "        count = 0\n",
    "        for lbl_i in range(len(real_label)):\n",
    "            if predicted_label[lbl_i] == real_label[lbl_i]:\n",
    "                count += 1\n",
    "        acc = count / len(real_label)\n",
    "        if acc > rbest_centroid:\n",
    "            rbest_centroid = acc\n",
    "            best_centroid = i\n",
    "            \n",
    "    for k in range(i, j):\n",
    "        s_index = index2[k]\n",
    "        wd = output_dict[\"bop_wd\"][s_index]\n",
    "        wl = output_dict[\"bop_wl\"][s_index]\n",
    "        bopf_t.bop(wd, wl, verbose=False)\n",
    "        test_bop_sort = sort_trim_arr(bopf_t.train_bop, output_dict[\"bop_feature_index2\"][s_index], \n",
    "                              bopf_t.m, output_dict[\"bop_fea_num2\"][s_index])\n",
    "        predicted_label = classify2(test_bop_sort, output_dict[\"bop_features2\"][s_index], bopf.tlabel, \n",
    "                           bopf_t.m, bopf.c, output_dict[\"bop_fea_num2\"][s_index])\n",
    "        real_label = np.array(bopf_t.labels)\n",
    "        count = 0\n",
    "        for lbl_i in range(len(real_label)):\n",
    "            if predicted_label[lbl_i] == real_label[lbl_i]:\n",
    "                count += 1\n",
    "        acc = count / len(real_label)\n",
    "        if acc > rbest_tf_idf:\n",
    "            rbest_tf_idf = acc\n",
    "            best_tf_idf = i\n",
    "            \n",
    "    out_q.put((rbest_centroid, best_centroid, rbest_tf_idf, best_tf_idf))\n",
    "        \n",
    "def main_test_ucr_p2_multiprocess(train_file, test_file, output_dict, top_n, n_process):\n",
    "    \n",
    "    m = mp.Manager()\n",
    "    result_queue = m.Queue()\n",
    "    \n",
    "    bopf = BagOfPatternFeature()\n",
    "    bopf.load_dataset(train_file, fmt=\"file\")\n",
    "    bopf.cumsum()\n",
    "    \n",
    "    index1 = np.argsort(output_dict[\"bop_cv_acc\"])[::-1]\n",
    "    index2 = np.argsort(output_dict[\"bop_cv_acc2\"])[::-1]\n",
    "    \n",
    "    N = 1 + (top_n // n_process)\n",
    "    jobs = []\n",
    "    for k in range(n_process):\n",
    "        i = k*N\n",
    "        j = (k+1)*N\n",
    "        if j > top_n:\n",
    "            j = top_n\n",
    "        jobs.append(mp.Process(target=worker_main_test_ucr_p2, \n",
    "                               args=(i, j, index1, index2, output_dict, bopf, test_file, result_queue)))\n",
    "        jobs[-1].start()\n",
    "    \n",
    "    for p in jobs:\n",
    "        p.join()\n",
    "        \n",
    "    best_centroid = -1\n",
    "    best_tf_idf = -1\n",
    "    rbest_centroid = -np.inf\n",
    "    rbest_tf_idf = -np.inf\n",
    "    \n",
    "    num_res = result_queue.size()\n",
    "    while num_ress > 0:\n",
    "        rbest_centroid_i, best_centroid_i, rbest_tf_idf_i, best_tf_idf_i = result_queue.get()\n",
    "        num_ress -= 1\n",
    "        if rbest_centroid_i > rbest_centroid:\n",
    "            best_centroid = best_centroid_i\n",
    "        if rbest_tf_idf_i > rbest_tf_idf:\n",
    "            best_tf_idf = best_tf_idf_i\n",
    "\n",
    "    s_index = index1[best_centroid]\n",
    "    print(\"classify with best centroid and wd:\", output_dict[\"bop_wd\"][s_index], \n",
    "          \", wl:\", output_dict[\"bop_wl\"][s_index], \n",
    "          \"-> cv_acc:\", round(output_dict[\"bop_cv_acc\"][s_index], 3),\n",
    "          \", acc:\", round(rbest_centroid, 3))\n",
    "    \n",
    "    s_index = index2[best_tf_idf]\n",
    "    print(\"classify with best tf-idf and wd:\", output_dict[\"bop_wd\"][s_index], \n",
    "          \", wl:\", output_dict[\"bop_wl\"][s_index], \n",
    "          \"-> cv_acc:\", round(output_dict[\"bop_cv_acc2\"][s_index], 3),\n",
    "          \", acc:\", round(rbest_tf_idf, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_file = \"D:/tesis/UCRArchive_2018/Adiac/Adiac_TRAIN.tsv\"\n",
    "test_file = \"D:/tesis/UCRArchive_2018/Adiac/Adiac_TEST.tsv\"\n",
    "bopf2, bopf_t2, output_dict2 = main_test_ucr_p1(train_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(\"./Untitled.ipynb\"), '..')))\n",
    "import numpy as np\n",
    "from src.bopf.bopf import BagOfPatternFeature\n",
    "from src.bopf.classifier import classify, classify2\n",
    "from src.utils import sort_trim_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 500\n",
      "TOTAL DE SEGMENTOS VACIOS:  41441\n",
      "best accuracy of CV:  0.35 , using the top 118 features according to ANOVA F\n",
      "best accuracy of CV2:  0.834 , using the top 790 features according to ANOVA F\n",
      "TOTAL DE SEGMENTOS VACIOS:  43393\n",
      "accuracy of classify using wd: 7 , wl: 0.325 , and best config for centroids is: 0.226\n",
      "accuracy of classify using wd: 7 , wl: 0.325 , and best config for tf-idf is: 0.168\n"
     ]
    }
   ],
   "source": [
    "bopf = BagOfPatternFeature(special_character=True)\n",
    "path = \"D:/tesis/tesis/data/plasticc_sub_dataset/\"\n",
    "bopf.load_dataset(path, fmt=\"npy\", set_type=\"train\", n1=500, n2=500, c=4)\n",
    "print(\"train size:\", bopf.m)\n",
    "bopf.cumsum()\n",
    "wd = 7 \n",
    "wl = 0.325\n",
    "bopf.bop(wd, wl)\n",
    "bopf.adjust_label_set()\n",
    "bopf.anova()\n",
    "bopf.anova_sort()\n",
    "bopf.sort_trim_arr()\n",
    "bopf.crossVL(verbose=False)\n",
    "print(\"best accuracy of CV: \", bopf.best_score, \", using the top\", bopf.best_idx, \"features according to ANOVA F\")\n",
    "bopf.crossVL2()\n",
    "print(\"best accuracy of CV2: \", bopf.best2_score, \", using the top\", bopf.best2_idx, \"features according to ANOVA F\")\n",
    "\n",
    "\n",
    "# load the test set\n",
    "bopf_t = BagOfPatternFeature(special_character=True)\n",
    "bopf_t.load_dataset(path, fmt=\"npy\", set_type=\"test\", n1=500, n2=500, c=4)\n",
    "\n",
    "# compute CUMSUM matrix for test set\n",
    "bopf_t.cumsum()\n",
    "\n",
    "# compute bag-of-pattern representation for test set\n",
    "bopf_t.bop(wd, wl)\n",
    "\n",
    "# sort and trim the bag-of-pattern representation based on the centroid best configuration\n",
    "test_bop_sort = sort_trim_arr(bopf_t.train_bop, bopf.sort_index[:bopf.best_idx], \n",
    "                                  bopf_t.m, bopf.best_idx)\n",
    "# classify to get predicted labels\n",
    "predicted_label = classify(test_bop_sort, bopf.crossL[:bopf. c*bopf.best_idx], bopf.tlabel, \n",
    "                               bopf_t.m, bopf.c, bopf.best_idx)\n",
    "\n",
    "# get real labels of test set\n",
    "real_label = np.array(bopf_t.labels)\n",
    "\n",
    "# compute accuracy\n",
    "count = 0\n",
    "for i in range(len(real_label)):\n",
    "    if predicted_label[i] == real_label[i]:\n",
    "        count += 1\n",
    "\n",
    "acc = count / bopf_t.m\n",
    "print(\"accuracy of classify using wd:\", wd, \", wl:\", wl, \", and best config for centroids is:\", acc)\n",
    "\n",
    "### repeat for tf-idf\n",
    "\n",
    "# sort and trim the bag-of-pattern representation based on the centroid best configuration\n",
    "test_bop_sort2 = sort_trim_arr(bopf_t.train_bop, bopf.sort_index[:bopf.best2_idx], \n",
    "                                  bopf_t.m, bopf.best2_idx)\n",
    "# classify to get predicted labels\n",
    "predicted_label2 = classify2(test_bop_sort2, bopf.crossL2[:bopf.c*bopf.best2_idx], bopf.tlabel, \n",
    "                               bopf_t.m, bopf.c, bopf.best2_idx)\n",
    "\n",
    "# compute accuracy\n",
    "count = 0\n",
    "for i in range(len(real_label)):\n",
    "    if predicted_label2[i] == real_label[i]:\n",
    "        count += 1\n",
    "        \n",
    "acc2 = count / len(real_label)\n",
    "print(\"accuracy of classify using wd:\", wd, \", wl:\", wl, \", and best config for tf-idf is:\", acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_test_plasticc_p1(n1, n2, c, wd_arr, wl_arr):\n",
    "    wd_num = len(wd_arr)\n",
    "    wl_num = len(wl_arr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    bopf = BagOfPatternFeature(special_character=True)\n",
    "    path = \"D:/tesis/tesis/data/plasticc_sub_dataset/\"\n",
    "    bopf.load_dataset(path, fmt=\"npy\", set_type=\"train\", n1=n1, c=c)\n",
    "    bopf.cumsum()\n",
    "    \n",
    "    bopf_t = BagOfPatternFeature(special_character=True)\n",
    "    bopf_t.load_dataset(path, fmt=\"npy\", set_type=\"test\", n1=n2, c=c)\n",
    "    bopf_t.cumsum()\n",
    "    \n",
    "    output_dict = defaultdict(list)\n",
    "    \n",
    "    for i in range(wd_num):\n",
    "        wd = wd_arr[i]\n",
    "        for j in range(wl_num):\n",
    "            wl = wl_arr[j]\n",
    "            print(\"wd: {}\".format(wd) + \", wl: {}\".format(wl), end=\"\\r\")\n",
    "            bopf.bop(wd, wl, verbose=False)\n",
    "            bopf.adjust_label_set()\n",
    "            bopf.anova(verbose=False)\n",
    "            bopf.anova_sort()\n",
    "            bopf.sort_trim_arr(verbose=False)\n",
    "            \n",
    "            bopf.crossVL(verbose=False)\n",
    "            output_dict[\"bop_features\"].append(bopf.crossL[:bopf.c*bopf.best_idx])\n",
    "            output_dict[\"bop_fea_num\"].append(bopf.best_idx)\n",
    "            output_dict[\"bop_cv_acc\"].append(bopf.best_score)\n",
    "            output_dict[\"bop_feature_index\"].append(bopf.sort_index[:bopf.best_idx])\n",
    "            \n",
    "            bopf.crossVL2()\n",
    "            output_dict[\"bop_features2\"].append(bopf.crossL2[:bopf.c*bopf.best2_idx])\n",
    "            output_dict[\"bop_fea_num2\"].append(bopf.best2_idx)\n",
    "            output_dict[\"bop_cv_acc2\"].append(bopf.best2_score)\n",
    "            output_dict[\"bop_feature_index2\"].append(bopf.sort_index[:bopf.best2_idx])\n",
    "            \n",
    "            output_dict[\"bop_wd\"].append(wd)\n",
    "            output_dict[\"bop_wl\"].append(wl)\n",
    "            \n",
    "    print(\"wd: {}\".format(wd) + \", wl: {0:.2f}\".format(wl))\n",
    "    return bopf, bopf_t, output_dict\n",
    "    \n",
    "def main_test_plasticc_p2(bopf, bopf_t, output_dict, top_n):\n",
    "    index1 = np.argsort(output_dict[\"bop_cv_acc\"])[::-1]\n",
    "    index2 = np.argsort(output_dict[\"bop_cv_acc2\"])[::-1]\n",
    "\n",
    "    best_centroid = -1\n",
    "    best_tf_idf = -1\n",
    "    rbest_centroid = -np.inf\n",
    "    rbest_tf_idf = -np.inf\n",
    "    for i in range(top_n):\n",
    "        print(i, end=\"\\r\")\n",
    "        s_index = index1[i]\n",
    "        wd = output_dict[\"bop_wd\"][s_index]\n",
    "        wl = output_dict[\"bop_wl\"][s_index]\n",
    "        bopf_t.bop(wd, wl, verbose=False)\n",
    "        test_bop_sort = sort_trim_arr(bopf_t.train_bop, output_dict[\"bop_feature_index\"][s_index], \n",
    "                                  bopf_t.m, output_dict[\"bop_fea_num\"][s_index])\n",
    "        predicted_label = classify(test_bop_sort, output_dict[\"bop_features\"][s_index], bopf.tlabel, \n",
    "                               bopf_t.m, bopf.c, output_dict[\"bop_fea_num\"][s_index])\n",
    "        real_label = np.array(bopf_t.labels)\n",
    "        count = 0\n",
    "        for j in range(len(real_label)):\n",
    "            if predicted_label[j] == real_label[j]:\n",
    "                count += 1\n",
    "        acc = count / len(real_label)\n",
    "        if acc > rbest_centroid:\n",
    "            rbest_centroid = acc\n",
    "            best_centroid = i\n",
    "    s_index1 = index1[best_centroid]\n",
    "    print(\"classify with best centroid and wd:\", output_dict[\"bop_wd\"][s_index1], \n",
    "          \", wl:\", output_dict[\"bop_wl\"][s_index1], \n",
    "          \"-> cv_acc:\", round(output_dict[\"bop_cv_acc\"][s_index1], 3),\n",
    "          \", acc:\", round(rbest_centroid, 3))\n",
    "    \n",
    "#     else:\n",
    "    # classify using tf-idf\n",
    "    # classify using centroid\n",
    "    for i in range(top_n):\n",
    "        print(i, end=\"\\r\")\n",
    "        s_index = index2[i]\n",
    "        wd = output_dict[\"bop_wd\"][s_index]\n",
    "        wl = output_dict[\"bop_wl\"][s_index]\n",
    "        bopf_t.bop(wd, wl, verbose=False)\n",
    "        test_bop_sort = sort_trim_arr(bopf_t.train_bop, output_dict[\"bop_feature_index2\"][s_index], \n",
    "                              bopf_t.m, output_dict[\"bop_fea_num2\"][s_index])\n",
    "        predicted_label = classify2(test_bop_sort, output_dict[\"bop_features2\"][s_index], bopf.tlabel, \n",
    "                           bopf_t.m, bopf.c, output_dict[\"bop_fea_num2\"][s_index])\n",
    "        real_label = np.array(bopf_t.labels)\n",
    "        count = 0\n",
    "        for j in range(len(real_label)):\n",
    "            if predicted_label[j] == real_label[j]:\n",
    "                count += 1\n",
    "        acc = count / len(real_label)\n",
    "        if acc > rbest_tf_idf:\n",
    "            rbest_tf_idf = acc\n",
    "            best_tf_idf = i\n",
    "            \n",
    "    s_index2 = index2[best_tf_idf]\n",
    "    print(\"classify with best tf-idf and wd:\", output_dict[\"bop_wd\"][s_index2], \n",
    "          \", wl:\", output_dict[\"bop_wl\"][s_index2], \n",
    "          \"-> cv_acc:\", round(output_dict[\"bop_cv_acc2\"][s_index2], 3),\n",
    "          \", acc:\", round(rbest_tf_idf, 3))\n",
    "    return max(round(rbest_tf_idf, 3), round(rbest_centroid, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
